{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perkdrew/image_classification/blob/master/image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXB8iQgFpYvo",
        "colab_type": "code",
        "outputId": "ed9b5344-093f-4ab9-bdbd-4f59a6adf0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.constraints import maxnorm\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Here we just make sure the image format is as desired. This will make the feature (x)\n",
        "# data - i.e. the RGB pixel values - for each image have the shape 3x32x32.\n",
        "if K.backend()=='tensorflow':\n",
        "    K.tensorflow_backend.set_image_dim_ordering('th')\n",
        "\n",
        "\n",
        "\n",
        "def getModel(CIF):\n",
        "    \"\"\"Specify the CNN architecture\"\"\"\n",
        "    weight_decay = 1e-4\n",
        "    model = Sequential()\n",
        "    #FEATURE DETECTION\n",
        "    #First layer\n",
        "    model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                     input_shape=(3,32,32),\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     padding = 'same', \n",
        "                     activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    #Second layer\n",
        "    model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                     padding = 'same', \n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     activation = 'relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    #Third layer\n",
        "    model.add(Conv2D(64, kernel_size=(3,3), \n",
        "                     padding = 'same', \n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    #Fourth layer\n",
        "    model.add(Conv2D(64,kernel_size=(3,3), \n",
        "                     padding = 'valid', \n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     activation = 'relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    #CLASSIFICATION\n",
        "    #Fully connected layer\n",
        "    model.add(Dense(512, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    #Output layer w/ softmax\n",
        "    model.add(Dense(CIF.num_classes, activation='softmax'))\n",
        "\n",
        "    #Compile the mode\n",
        "    opt_rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-6, decay=1e-6)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['acc'])\n",
        "    #model.summary()\n",
        "    return model\n",
        "  \n",
        "  \n",
        "def fitModel(model, CIF):\n",
        "    \"\"\"Fit the model to data\"\"\"\n",
        "    early = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=5, \n",
        "                              mode='auto')\n",
        "    \n",
        "    checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', \n",
        "                                   save_best_only=True)\n",
        "    \n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                                  factor=0.1,\n",
        "                                  patience=2, \n",
        "                                  min_lr=1e-8)\n",
        "    \n",
        "    model.fit(CIF.x_train, CIF.y_train,\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          validation_data=(CIF.x_valid, CIF.y_valid), \n",
        "          callbacks=[checkpointer, reduce_lr, early])\n",
        "    model.load_weights('/tmp/weights.hdf5')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def runImageClassification(getModel=None,fitModel=None,seed=7):\n",
        "    # Fetch data. You may need to be connected to the internet the first time this is done.\n",
        "    # After the first time, it should be available in your system. On the off chance this\n",
        "    # is not the case on your system and you find yourself repeatedly downloading the data, \n",
        "    # you should change this code so you can load the data once and pass it to this function. \n",
        "    print(\"Preparing data...\")\n",
        "    data=CIFAR(seed)\n",
        "        \n",
        "    # Create model \n",
        "    print(\"Creating model...\")\n",
        "    model=getModel(data)\n",
        "    \n",
        "    # Fit model\n",
        "    print(\"Fitting model...\")\n",
        "    model=fitModel(model,data)\n",
        "\n",
        "    # Evaluate on test data\n",
        "    print(\"Evaluating model...\")\n",
        "    score = model.evaluate(data.x_test, data.y_test, verbose=0)\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "class CIFAR:\n",
        "    def __init__(self,seed=0):\n",
        "        # Get and split data\n",
        "        data = self.__getData(seed)\n",
        "        self.x_train_raw=data[0][0]\n",
        "        self.y_train_raw=data[0][1]\n",
        "        self.x_valid_raw=data[1][0]\n",
        "        self.y_valid_raw=data[1][1]\n",
        "        self.x_test_raw=data[2][0]\n",
        "        self.y_test_raw=data[2][1]\n",
        "        # Record input/output dimensions\n",
        "        self.num_classes=10\n",
        "        self.input_dim=self.x_train_raw.shape[1:]\n",
        "         # Convert data\n",
        "        self.y_train = np_utils.to_categorical(self.y_train_raw, self.num_classes)\n",
        "        self.y_valid = np_utils.to_categorical(self.y_valid_raw, self.num_classes)\n",
        "        self.y_test = np_utils.to_categorical(self.y_test_raw, self.num_classes)\n",
        "        self.x_train = self.x_train_raw.astype('float32')\n",
        "        self.x_valid = self.x_valid_raw.astype('float32')\n",
        "        self.x_test = self.x_test_raw.astype('float32')\n",
        "        self.x_train  /= 255\n",
        "        self.x_valid  /= 255\n",
        "        self.x_test /= 255\n",
        "        # Class names\n",
        "        self.class_names=['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "\n",
        "    def __getData (self,seed=0):\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        return self.__shuffleData(x_train,y_train,x_test,y_test,seed)\n",
        "    \n",
        "    def __shuffleData (self,x_train,y_train,x_test,y_test,seed=0):\n",
        "        tr_perc=.75\n",
        "        va_perc=.15\n",
        "        x=np.concatenate((x_train,x_test))\n",
        "        y=np.concatenate((y_train,y_test))\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(x)\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(y)\n",
        "        indices = np.random.permutation(len(x))\n",
        "        tr=round(len(x)*tr_perc)\n",
        "        va=round(len(x)*va_perc)\n",
        "        self.tr_indices=indices[0:tr]\n",
        "        self.va_indices=indices[tr:(tr+va)]\n",
        "        self.te_indices=indices[(tr+va):len(x)]\n",
        "        x_tr=x[self.tr_indices,]\n",
        "        x_va=x[self.va_indices,]\n",
        "        x_te=x[self.te_indices,]\n",
        "        y_tr=y[self.tr_indices,]\n",
        "        y_va=y[self.va_indices,]\n",
        "        y_te=y[self.te_indices,]\n",
        "        return ((x_tr,y_tr),(x_va,y_va),(x_te,y_te))\n",
        "\n",
        "    # Print figure with 10 random images, one from each class\n",
        "    def showImages(self):\n",
        "        fig = plt.figure(figsize=(8,3))\n",
        "        for i in range(self.num_classes):\n",
        "            ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "            idx = np.where(self.y_valid_raw[:]==i)[0]\n",
        "            features_idx = self.x_valid_raw[idx,::]\n",
        "            img_num = np.random.randint(features_idx.shape[0])\n",
        "            im = np.transpose(features_idx[img_num,::],(1,2,0))\n",
        "            ax.set_title(self.class_names[i])\n",
        "            plt.imshow(im)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "runImageClassification(getModel=getModel,fitModel=fitModel,seed=7)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing data...\n",
            "Creating model...\n",
            "Fitting model...\n",
            "Train on 45000 samples, validate on 9000 samples\n",
            "Epoch 1/100\n",
            "45000/45000 [==============================] - 19s 419us/step - loss: 2.1306 - acc: 0.3147 - val_loss: 1.5262 - val_acc: 0.4493\n",
            "Epoch 2/100\n",
            "45000/45000 [==============================] - 17s 371us/step - loss: 1.4335 - acc: 0.4914 - val_loss: 1.2433 - val_acc: 0.5623\n",
            "Epoch 3/100\n",
            "45000/45000 [==============================] - 16s 364us/step - loss: 1.2404 - acc: 0.5689 - val_loss: 1.1532 - val_acc: 0.6060\n",
            "Epoch 4/100\n",
            "45000/45000 [==============================] - 17s 368us/step - loss: 1.1066 - acc: 0.6182 - val_loss: 0.9693 - val_acc: 0.6643\n",
            "Epoch 5/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 1.0010 - acc: 0.6571 - val_loss: 0.8420 - val_acc: 0.7122\n",
            "Epoch 6/100\n",
            "45000/45000 [==============================] - 17s 370us/step - loss: 0.9100 - acc: 0.6885 - val_loss: 0.8033 - val_acc: 0.7260\n",
            "Epoch 7/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.8491 - acc: 0.7115 - val_loss: 0.7634 - val_acc: 0.7443\n",
            "Epoch 8/100\n",
            "45000/45000 [==============================] - 17s 368us/step - loss: 0.7956 - acc: 0.7324 - val_loss: 0.7414 - val_acc: 0.7502\n",
            "Epoch 9/100\n",
            "45000/45000 [==============================] - 17s 368us/step - loss: 0.7560 - acc: 0.7462 - val_loss: 0.6967 - val_acc: 0.7659\n",
            "Epoch 10/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.7189 - acc: 0.7573 - val_loss: 0.7520 - val_acc: 0.7511\n",
            "Epoch 11/100\n",
            "45000/45000 [==============================] - 17s 368us/step - loss: 0.6901 - acc: 0.7714 - val_loss: 0.6665 - val_acc: 0.7802\n",
            "Epoch 12/100\n",
            "45000/45000 [==============================] - 17s 369us/step - loss: 0.6596 - acc: 0.7802 - val_loss: 0.6705 - val_acc: 0.7782\n",
            "Epoch 13/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.6337 - acc: 0.7933 - val_loss: 0.6581 - val_acc: 0.7802\n",
            "Epoch 14/100\n",
            "45000/45000 [==============================] - 16s 366us/step - loss: 0.6172 - acc: 0.7979 - val_loss: 0.6549 - val_acc: 0.7891\n",
            "Epoch 15/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.5940 - acc: 0.8038 - val_loss: 0.6627 - val_acc: 0.7840\n",
            "Epoch 16/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.5745 - acc: 0.8122 - val_loss: 0.6453 - val_acc: 0.7862\n",
            "Epoch 17/100\n",
            "45000/45000 [==============================] - 17s 370us/step - loss: 0.5607 - acc: 0.8168 - val_loss: 0.6011 - val_acc: 0.8064\n",
            "Epoch 18/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.5452 - acc: 0.8228 - val_loss: 0.6159 - val_acc: 0.7977\n",
            "Epoch 19/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.5300 - acc: 0.8298 - val_loss: 0.6754 - val_acc: 0.7794\n",
            "Epoch 20/100\n",
            "45000/45000 [==============================] - 17s 369us/step - loss: 0.4590 - acc: 0.8530 - val_loss: 0.5889 - val_acc: 0.8080\n",
            "Epoch 21/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.4418 - acc: 0.8596 - val_loss: 0.5757 - val_acc: 0.8122\n",
            "Epoch 22/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.4343 - acc: 0.8618 - val_loss: 0.5746 - val_acc: 0.8154\n",
            "Epoch 23/100\n",
            "45000/45000 [==============================] - 17s 369us/step - loss: 0.4274 - acc: 0.8646 - val_loss: 0.5746 - val_acc: 0.8138\n",
            "Epoch 24/100\n",
            "45000/45000 [==============================] - 17s 368us/step - loss: 0.4169 - acc: 0.8675 - val_loss: 0.5714 - val_acc: 0.8163\n",
            "Epoch 25/100\n",
            "45000/45000 [==============================] - 16s 366us/step - loss: 0.4163 - acc: 0.8683 - val_loss: 0.5722 - val_acc: 0.8166\n",
            "Epoch 26/100\n",
            "45000/45000 [==============================] - 17s 371us/step - loss: 0.4151 - acc: 0.8704 - val_loss: 0.5696 - val_acc: 0.8170\n",
            "Epoch 27/100\n",
            "45000/45000 [==============================] - 16s 366us/step - loss: 0.4069 - acc: 0.8718 - val_loss: 0.5669 - val_acc: 0.8177\n",
            "Epoch 28/100\n",
            "45000/45000 [==============================] - 17s 369us/step - loss: 0.4018 - acc: 0.8729 - val_loss: 0.5657 - val_acc: 0.8163\n",
            "Epoch 29/100\n",
            "45000/45000 [==============================] - 17s 368us/step - loss: 0.3939 - acc: 0.8763 - val_loss: 0.5688 - val_acc: 0.8181\n",
            "Epoch 30/100\n",
            "45000/45000 [==============================] - 16s 367us/step - loss: 0.3903 - acc: 0.8756 - val_loss: 0.5712 - val_acc: 0.8167\n",
            "Epoch 31/100\n",
            "45000/45000 [==============================] - 17s 369us/step - loss: 0.3902 - acc: 0.8779 - val_loss: 0.5677 - val_acc: 0.8189\n",
            "Epoch 32/100\n",
            "45000/45000 [==============================] - 17s 367us/step - loss: 0.3893 - acc: 0.8790 - val_loss: 0.5665 - val_acc: 0.8202\n",
            "Epoch 33/100\n",
            "45000/45000 [==============================] - 16s 366us/step - loss: 0.3873 - acc: 0.8748 - val_loss: 0.5664 - val_acc: 0.8199\n",
            "Evaluating model...\n",
            "Test accuracy: 0.8146666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcyVcoRKKJIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}