{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXB8iQgFpYvo",
        "colab_type": "code",
        "outputId": "d964cba0-aca5-4bbb-f393-d32579331536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.constraints import maxnorm\n",
        "from keras.optimizers import Adam\n",
        "#from keras.regularizers import l1, l2\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Here we just make sure the image format is as desired. This will make the feature (x)\n",
        "# data - i.e. the RGB pixel values - for each image have the shape 3x32x32.\n",
        "if K.backend()=='tensorflow':\n",
        "    K.tensorflow_backend.set_image_dim_ordering('th')\n",
        "\n",
        "\n",
        "\n",
        "def getModel(CIFAR):\n",
        "    \"\"\"Specify the CNN architecture\"\"\"\n",
        "    model = Sequential()\n",
        "    #FEATURE DETECTION\n",
        "    #First layer\n",
        "    model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                     input_shape=(3,32,32), \n",
        "                     padding = 'same', \n",
        "                     activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    #Second layer\n",
        "    model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                     padding = 'same', \n",
        "                     activation = 'relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    #Third layer\n",
        "    model.add(Conv2D(64, kernel_size=(3,3), \n",
        "                     padding = 'same', \n",
        "                     activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    #Fourth layer\n",
        "    model.add(Conv2D(64,kernel_size=(3,3), \n",
        "                     padding = 'same', \n",
        "                     activation = 'relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    #CLASSIFICATION\n",
        "    #Fully connected layer\n",
        "    model.add(Dense(512, activation = 'relu', \n",
        "                    kernel_constraint=maxnorm(3)))\n",
        "    model.add(Dropout(0.5))\n",
        "    #Output layer w/ softmax\n",
        "    model.add(Dense(CIFAR.num_classes, \n",
        "                    activation='softmax', \n",
        "                    kernel_constraint=maxnorm(3)))\n",
        "\n",
        "    #Compile the mode\n",
        "    model.compile(Adam(lr=0.001), \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "    #model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def fitModel(model, CIFAR):\n",
        "    \"\"\"Fit the CNN model to data\"\"\"\n",
        "    model.save_weights('/tmp/weights.hdf5')\n",
        "    early = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=5,\n",
        "                              verbose=0, \n",
        "                              mode='auto')\n",
        "    checkpointer = ModelCheckpoint(filepath='/tmp/weights.hdf5', \n",
        "                                   verbose=0, \n",
        "                                   save_best_only=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                                  factor=0.1,\n",
        "                                  patience=2, \n",
        "                                  min_lr=1e-8)\n",
        "    model.fit(CIFAR.x_train, CIFAR.y_train,\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          verbose=0, \n",
        "          validation_data=(CIFAR.x_valid, CIFAR.y_valid), \n",
        "          callbacks=[reduce_lr, checkpointer, early])\n",
        "    model.load_weights(filepath='/tmp/weights.hdf5')\n",
        "    #scores = model.evaluate(CIFAR.x_valid, CIFAR.y_valid, verbose=1)\n",
        "    #print('Accuracy: {:.2f}'.format(scores[1]))\n",
        "    return model\n",
        "\n",
        "\n",
        "def runImageClassification(getModel=None,fitModel=None,seed=7):\n",
        "    # Fetch data. You may need to be connected to the internet the first time this is done.\n",
        "    # After the first time, it should be available in your system. On the off chance this\n",
        "    # is not the case on your system and you find yourself repeatedly downloading the data, \n",
        "    # you should change this code so you can load the data once and pass it to this function. \n",
        "    print(\"Preparing data...\")\n",
        "    data=CIFAR(seed)\n",
        "        \n",
        "    # Create model \n",
        "    print(\"Creating model...\")\n",
        "    model=getModel(data)\n",
        "    \n",
        "    # Fit model\n",
        "    print(\"Fitting model...\")\n",
        "    model=fitModel(model,data)\n",
        "\n",
        "    # Evaluate on test data\n",
        "    print(\"Evaluating model...\")\n",
        "    score = model.evaluate(data.x_test, data.y_test, verbose=0)\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "class CIFAR:\n",
        "    def __init__(self,seed=0):\n",
        "        # Get and split data\n",
        "        data = self.__getData(seed)\n",
        "        self.x_train_raw=data[0][0]\n",
        "        self.y_train_raw=data[0][1]\n",
        "        self.x_valid_raw=data[1][0]\n",
        "        self.y_valid_raw=data[1][1]\n",
        "        self.x_test_raw=data[2][0]\n",
        "        self.y_test_raw=data[2][1]\n",
        "        # Record input/output dimensions\n",
        "        self.num_classes=10\n",
        "        self.input_dim=self.x_train_raw.shape[1:]\n",
        "         # Convert data\n",
        "        self.y_train = np_utils.to_categorical(self.y_train_raw, self.num_classes)\n",
        "        self.y_valid = np_utils.to_categorical(self.y_valid_raw, self.num_classes)\n",
        "        self.y_test = np_utils.to_categorical(self.y_test_raw, self.num_classes)\n",
        "        self.x_train = self.x_train_raw.astype('float32')\n",
        "        self.x_valid = self.x_valid_raw.astype('float32')\n",
        "        self.x_test = self.x_test_raw.astype('float32')\n",
        "        self.x_train  /= 255\n",
        "        self.x_valid  /= 255\n",
        "        self.x_test /= 255\n",
        "        # Class names\n",
        "        self.class_names=['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "\n",
        "    def __getData (self,seed=0):\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        return self.__shuffleData(x_train,y_train,x_test,y_test,seed)\n",
        "    \n",
        "    def __shuffleData (self,x_train,y_train,x_test,y_test,seed=0):\n",
        "        tr_perc=.75\n",
        "        va_perc=.15\n",
        "        x=np.concatenate((x_train,x_test))\n",
        "        y=np.concatenate((y_train,y_test))\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(x)\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(y)\n",
        "        indices = np.random.permutation(len(x))\n",
        "        tr=round(len(x)*tr_perc)\n",
        "        va=round(len(x)*va_perc)\n",
        "        self.tr_indices=indices[0:tr]\n",
        "        self.va_indices=indices[tr:(tr+va)]\n",
        "        self.te_indices=indices[(tr+va):len(x)]\n",
        "        x_tr=x[self.tr_indices,]\n",
        "        x_va=x[self.va_indices,]\n",
        "        x_te=x[self.te_indices,]\n",
        "        y_tr=y[self.tr_indices,]\n",
        "        y_va=y[self.va_indices,]\n",
        "        y_te=y[self.te_indices,]\n",
        "        return ((x_tr,y_tr),(x_va,y_va),(x_te,y_te))\n",
        "\n",
        "    # Print figure with 10 random images, one from each class\n",
        "    def showImages(self):\n",
        "        fig = plt.figure(figsize=(8,3))\n",
        "        for i in range(self.num_classes):\n",
        "            ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "            idx = np.where(self.y_valid_raw[:]==i)[0]\n",
        "            features_idx = self.x_valid_raw[idx,::]\n",
        "            img_num = np.random.randint(features_idx.shape[0])\n",
        "            im = np.transpose(features_idx[img_num,::],(1,2,0))\n",
        "            ax.set_title(self.class_names[i])\n",
        "            plt.imshow(im)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "#MyGetModel = getModel(CIFAR())\n",
        "#MyFitModel = fitModel(getModel(CIFAR()), CIFAR())\n",
        "\n",
        "runImageClassification(getModel=getModel,fitModel=fitModel,seed=7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing data...\n",
            "Creating model...\n",
            "Fitting model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3158d6e6e407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;31m#MyFitModel = fitModel(getModel(CIFAR()), CIFAR())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m \u001b[0mrunImageClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfitModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-3158d6e6e407>\u001b[0m in \u001b[0;36mrunImageClassification\u001b[0;34m(getModel, fitModel, seed)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfitModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Evaluate on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-3158d6e6e407>\u001b[0m in \u001b[0;36mfitModel\u001b[0;34m(model, CIFAR)\u001b[0m\n\u001b[1;32m     94\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCIFAR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m           callbacks=[reduce_lr, checkpointer, early])\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m#scores = model.evaluate(CIFAR.x_valid, CIFAR.y_valid, verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}