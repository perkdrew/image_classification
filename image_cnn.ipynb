{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perkdrew/image_classification/blob/master/image_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXB8iQgFpYvo",
        "colab_type": "code",
        "outputId": "dba31683-3ddc-48ec-8439-0498a0bfa32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.constraints import maxnorm\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Here we just make sure the image format is as desired. This will make the feature (x)\n",
        "# data - i.e. the RGB pixel values - for each image have the shape 3x32x32.\n",
        "if K.backend()=='tensorflow':\n",
        "    K.tensorflow_backend.set_image_dim_ordering('th')\n",
        "\n",
        "\n",
        "\n",
        "def myGetModel(CIF):\n",
        "    \"\"\"Specify the CNN architecture\"\"\"\n",
        "    weight_decay = 1e-4\n",
        "    model = Sequential()\n",
        "    #FEATURE DETECTION\n",
        "    #First layer\n",
        "    model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                     input_shape=(3,32,32),\n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     padding = 'same', \n",
        "                     activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    #Second layer\n",
        "    model.add(Conv2D(32, kernel_size=(3,3), \n",
        "                     padding = 'same', \n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     activation = 'relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    #Third layer\n",
        "    model.add(Conv2D(64, kernel_size=(3,3), \n",
        "                     padding = 'same', \n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "    #Fourth layer\n",
        "    model.add(Conv2D(64,kernel_size=(3,3), \n",
        "                     padding = 'valid', \n",
        "                     kernel_regularizer=regularizers.l2(weight_decay),\n",
        "                     activation = 'relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Flatten())\n",
        "    #CLASSIFICATION\n",
        "    #Fully connected layer\n",
        "    model.add(Dense(512, activation = 'relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    #Output layer w/ softmax\n",
        "    model.add(Dense(CIF.num_classes, activation='softmax'))\n",
        "\n",
        "    #Compile the mode\n",
        "    opt_rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-6, decay=1e-6)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['acc'])\n",
        "    #model.summary()\n",
        "    return model\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate\n",
        "  \n",
        "def myFitModel(model, CIF):\n",
        "    \"\"\"Fit the model to data\"\"\"\n",
        "    early = EarlyStopping(monitor='val_loss',\n",
        "                              min_delta=0,\n",
        "                              patience=10, \n",
        "                              mode='auto')\n",
        "    \n",
        "    checkpointer = ModelCheckpoint(filepath='/tmp/weights-best.hdf5', \n",
        "                                   save_best_only=True)\n",
        "    \n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                                  factor=0.1,\n",
        "                                  patience=5, \n",
        "                                  min_lr=1e-8)\n",
        "    \n",
        "    model.fit(CIF.x_train, CIF.y_train,\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          validation_data=(CIF.x_valid, CIF.y_valid), \n",
        "          callbacks=[LearningRateScheduler(lr_schedule), checkpointer, reduce_lr, early])\n",
        "    model.load_weights('/tmp/weights-best.hdf5')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def runImageClassification(getModel=None,fitModel=None,seed=7):\n",
        "    # Fetch data. You may need to be connected to the internet the first time this is done.\n",
        "    # After the first time, it should be available in your system. On the off chance this\n",
        "    # is not the case on your system and you find yourself repeatedly downloading the data, \n",
        "    # you should change this code so you can load the data once and pass it to this function. \n",
        "    print(\"Preparing data...\")\n",
        "    data=CIFAR(seed)\n",
        "        \n",
        "    # Create model \n",
        "    print(\"Creating model...\")\n",
        "    model=getModel(data)\n",
        "    \n",
        "    # Fit model\n",
        "    print(\"Fitting model...\")\n",
        "    model=fitModel(model,data)\n",
        "\n",
        "    # Evaluate on test data\n",
        "    print(\"Evaluating model...\")\n",
        "    score = model.evaluate(data.x_test, data.y_test, verbose=0)\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "class CIFAR:\n",
        "    def __init__(self,seed=0):\n",
        "        # Get and split data\n",
        "        data = self.__getData(seed)\n",
        "        self.x_train_raw=data[0][0]\n",
        "        self.y_train_raw=data[0][1]\n",
        "        self.x_valid_raw=data[1][0]\n",
        "        self.y_valid_raw=data[1][1]\n",
        "        self.x_test_raw=data[2][0]\n",
        "        self.y_test_raw=data[2][1]\n",
        "        # Record input/output dimensions\n",
        "        self.num_classes=10\n",
        "        self.input_dim=self.x_train_raw.shape[1:]\n",
        "         # Convert data\n",
        "        self.y_train = np_utils.to_categorical(self.y_train_raw, self.num_classes)\n",
        "        self.y_valid = np_utils.to_categorical(self.y_valid_raw, self.num_classes)\n",
        "        self.y_test = np_utils.to_categorical(self.y_test_raw, self.num_classes)\n",
        "        self.x_train = self.x_train_raw.astype('float32')\n",
        "        self.x_valid = self.x_valid_raw.astype('float32')\n",
        "        self.x_test = self.x_test_raw.astype('float32')\n",
        "        self.x_train  /= 255\n",
        "        self.x_valid  /= 255\n",
        "        self.x_test /= 255\n",
        "        # Class names\n",
        "        self.class_names=['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "\n",
        "    def __getData (self,seed=0):\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        return self.__shuffleData(x_train,y_train,x_test,y_test,seed)\n",
        "    \n",
        "    def __shuffleData (self,x_train,y_train,x_test,y_test,seed=0):\n",
        "        tr_perc=.75\n",
        "        va_perc=.15\n",
        "        x=np.concatenate((x_train,x_test))\n",
        "        y=np.concatenate((y_train,y_test))\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(x)\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(y)\n",
        "        indices = np.random.permutation(len(x))\n",
        "        tr=round(len(x)*tr_perc)\n",
        "        va=round(len(x)*va_perc)\n",
        "        self.tr_indices=indices[0:tr]\n",
        "        self.va_indices=indices[tr:(tr+va)]\n",
        "        self.te_indices=indices[(tr+va):len(x)]\n",
        "        x_tr=x[self.tr_indices,]\n",
        "        x_va=x[self.va_indices,]\n",
        "        x_te=x[self.te_indices,]\n",
        "        y_tr=y[self.tr_indices,]\n",
        "        y_va=y[self.va_indices,]\n",
        "        y_te=y[self.te_indices,]\n",
        "        return ((x_tr,y_tr),(x_va,y_va),(x_te,y_te))\n",
        "\n",
        "    # Print figure with 10 random images, one from each class\n",
        "    def showImages(self):\n",
        "        fig = plt.figure(figsize=(8,3))\n",
        "        for i in range(self.num_classes):\n",
        "            ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
        "            idx = np.where(self.y_valid_raw[:]==i)[0]\n",
        "            features_idx = self.x_valid_raw[idx,::]\n",
        "            img_num = np.random.randint(features_idx.shape[0])\n",
        "            im = np.transpose(features_idx[img_num,::],(1,2,0))\n",
        "            ax.set_title(self.class_names[i])\n",
        "            plt.imshow(im)\n",
        "        plt.show()\n",
        "        "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing data...\n",
            "Creating model...\n",
            "Fitting model...\n",
            "Train on 45000 samples, validate on 9000 samples\n",
            "Epoch 1/100\n",
            "45000/45000 [==============================] - 18s 404us/step - loss: 2.1185 - acc: 0.3262 - val_loss: 1.5134 - val_acc: 0.4516\n",
            "Epoch 2/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 1.4152 - acc: 0.4995 - val_loss: 1.2043 - val_acc: 0.5778\n",
            "Epoch 3/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 1.2232 - acc: 0.5747 - val_loss: 1.0264 - val_acc: 0.6417\n",
            "Epoch 4/100\n",
            "45000/45000 [==============================] - 15s 339us/step - loss: 1.1019 - acc: 0.6164 - val_loss: 1.0203 - val_acc: 0.6484\n",
            "Epoch 5/100\n",
            "45000/45000 [==============================] - 15s 339us/step - loss: 0.9996 - acc: 0.6584 - val_loss: 0.8726 - val_acc: 0.6997\n",
            "Epoch 6/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.9242 - acc: 0.6818 - val_loss: 0.8085 - val_acc: 0.7246\n",
            "Epoch 7/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.8605 - acc: 0.7069 - val_loss: 0.8385 - val_acc: 0.7207\n",
            "Epoch 8/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.8170 - acc: 0.7248 - val_loss: 0.7319 - val_acc: 0.7594\n",
            "Epoch 9/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.7734 - acc: 0.7388 - val_loss: 0.7037 - val_acc: 0.7632\n",
            "Epoch 10/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.7360 - acc: 0.7509 - val_loss: 0.6954 - val_acc: 0.7697\n",
            "Epoch 11/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.7092 - acc: 0.7618 - val_loss: 0.6684 - val_acc: 0.7793\n",
            "Epoch 12/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.6770 - acc: 0.7724 - val_loss: 0.6670 - val_acc: 0.7794\n",
            "Epoch 13/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.6561 - acc: 0.7814 - val_loss: 0.6918 - val_acc: 0.7716\n",
            "Epoch 14/100\n",
            "45000/45000 [==============================] - 15s 339us/step - loss: 0.6340 - acc: 0.7896 - val_loss: 0.6328 - val_acc: 0.7894\n",
            "Epoch 15/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.6113 - acc: 0.7975 - val_loss: 0.6171 - val_acc: 0.7986\n",
            "Epoch 16/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.6013 - acc: 0.8013 - val_loss: 0.6097 - val_acc: 0.7981\n",
            "Epoch 17/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.5840 - acc: 0.8076 - val_loss: 0.6355 - val_acc: 0.7953\n",
            "Epoch 18/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.5655 - acc: 0.8136 - val_loss: 0.6657 - val_acc: 0.7854\n",
            "Epoch 19/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.5575 - acc: 0.8152 - val_loss: 0.6153 - val_acc: 0.8008\n",
            "Epoch 20/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.5397 - acc: 0.8227 - val_loss: 0.6023 - val_acc: 0.8013\n",
            "Epoch 21/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.5296 - acc: 0.8255 - val_loss: 0.5941 - val_acc: 0.8062\n",
            "Epoch 22/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.5169 - acc: 0.8296 - val_loss: 0.6034 - val_acc: 0.8019\n",
            "Epoch 23/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.5028 - acc: 0.8355 - val_loss: 0.6063 - val_acc: 0.8028\n",
            "Epoch 24/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.4955 - acc: 0.8385 - val_loss: 0.5760 - val_acc: 0.8144\n",
            "Epoch 25/100\n",
            "45000/45000 [==============================] - 15s 340us/step - loss: 0.4853 - acc: 0.8443 - val_loss: 0.6127 - val_acc: 0.8017\n",
            "Epoch 26/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.4770 - acc: 0.8445 - val_loss: 0.5921 - val_acc: 0.8049\n",
            "Epoch 27/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.4668 - acc: 0.8482 - val_loss: 0.5863 - val_acc: 0.8096\n",
            "Epoch 28/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.4645 - acc: 0.8496 - val_loss: 0.5791 - val_acc: 0.8134\n",
            "Epoch 29/100\n",
            "45000/45000 [==============================] - 15s 339us/step - loss: 0.4497 - acc: 0.8536 - val_loss: 0.5987 - val_acc: 0.8066\n",
            "Epoch 30/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.4497 - acc: 0.8548 - val_loss: 0.5711 - val_acc: 0.8162\n",
            "Epoch 31/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.4331 - acc: 0.8590 - val_loss: 0.5690 - val_acc: 0.8129\n",
            "Epoch 32/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.4287 - acc: 0.8608 - val_loss: 0.5798 - val_acc: 0.8127\n",
            "Epoch 33/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.4206 - acc: 0.8656 - val_loss: 0.5832 - val_acc: 0.8120\n",
            "Epoch 34/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.4209 - acc: 0.8635 - val_loss: 0.5551 - val_acc: 0.8206\n",
            "Epoch 35/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.4094 - acc: 0.8681 - val_loss: 0.5665 - val_acc: 0.8207\n",
            "Epoch 36/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.4015 - acc: 0.8713 - val_loss: 0.5816 - val_acc: 0.8129\n",
            "Epoch 37/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.4047 - acc: 0.8698 - val_loss: 0.5580 - val_acc: 0.8196\n",
            "Epoch 38/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3934 - acc: 0.8731 - val_loss: 0.5598 - val_acc: 0.8233\n",
            "Epoch 39/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3875 - acc: 0.8754 - val_loss: 0.5688 - val_acc: 0.8177\n",
            "Epoch 40/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3861 - acc: 0.8762 - val_loss: 0.5472 - val_acc: 0.8237\n",
            "Epoch 41/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3791 - acc: 0.8773 - val_loss: 0.5640 - val_acc: 0.8200\n",
            "Epoch 42/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3773 - acc: 0.8803 - val_loss: 0.5486 - val_acc: 0.8219\n",
            "Epoch 43/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3687 - acc: 0.8829 - val_loss: 0.5659 - val_acc: 0.8181\n",
            "Epoch 44/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3657 - acc: 0.8824 - val_loss: 0.5639 - val_acc: 0.8192\n",
            "Epoch 45/100\n",
            "45000/45000 [==============================] - 15s 340us/step - loss: 0.3636 - acc: 0.8831 - val_loss: 0.5519 - val_acc: 0.8226\n",
            "Epoch 46/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3586 - acc: 0.8855 - val_loss: 0.5530 - val_acc: 0.8204\n",
            "Epoch 47/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3681 - acc: 0.8821 - val_loss: 0.5633 - val_acc: 0.8191\n",
            "Epoch 48/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3501 - acc: 0.8890 - val_loss: 0.5495 - val_acc: 0.8262\n",
            "Epoch 49/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3527 - acc: 0.8891 - val_loss: 0.5418 - val_acc: 0.8261\n",
            "Epoch 50/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3488 - acc: 0.8901 - val_loss: 0.5448 - val_acc: 0.8252\n",
            "Epoch 51/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3481 - acc: 0.8909 - val_loss: 0.5566 - val_acc: 0.8256\n",
            "Epoch 52/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3409 - acc: 0.8916 - val_loss: 0.5604 - val_acc: 0.8214\n",
            "Epoch 53/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3360 - acc: 0.8943 - val_loss: 0.5492 - val_acc: 0.8260\n",
            "Epoch 54/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3330 - acc: 0.8935 - val_loss: 0.5478 - val_acc: 0.8250\n",
            "Epoch 55/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3307 - acc: 0.8959 - val_loss: 0.5468 - val_acc: 0.8280\n",
            "Epoch 56/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3253 - acc: 0.8978 - val_loss: 0.5487 - val_acc: 0.8268\n",
            "Epoch 57/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3278 - acc: 0.8979 - val_loss: 0.5462 - val_acc: 0.8292\n",
            "Epoch 58/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3211 - acc: 0.8993 - val_loss: 0.5474 - val_acc: 0.8280\n",
            "Epoch 59/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3197 - acc: 0.8999 - val_loss: 0.5373 - val_acc: 0.8281\n",
            "Epoch 60/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3197 - acc: 0.8997 - val_loss: 0.5395 - val_acc: 0.8278\n",
            "Epoch 61/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.3096 - acc: 0.9027 - val_loss: 0.5355 - val_acc: 0.8297\n",
            "Epoch 62/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.3108 - acc: 0.9048 - val_loss: 0.5447 - val_acc: 0.8338\n",
            "Epoch 63/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3138 - acc: 0.9029 - val_loss: 0.5462 - val_acc: 0.8306\n",
            "Epoch 64/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3062 - acc: 0.9053 - val_loss: 0.5602 - val_acc: 0.8207\n",
            "Epoch 65/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3031 - acc: 0.9051 - val_loss: 0.5560 - val_acc: 0.8254\n",
            "Epoch 66/100\n",
            "45000/45000 [==============================] - 15s 340us/step - loss: 0.3054 - acc: 0.9047 - val_loss: 0.5354 - val_acc: 0.8294\n",
            "Epoch 67/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2977 - acc: 0.9089 - val_loss: 0.5600 - val_acc: 0.8283\n",
            "Epoch 68/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.3017 - acc: 0.9071 - val_loss: 0.5617 - val_acc: 0.8273\n",
            "Epoch 69/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.2954 - acc: 0.9072 - val_loss: 0.5472 - val_acc: 0.8282\n",
            "Epoch 70/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2968 - acc: 0.9080 - val_loss: 0.5397 - val_acc: 0.8331\n",
            "Epoch 71/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2927 - acc: 0.9122 - val_loss: 0.5427 - val_acc: 0.8300\n",
            "Epoch 72/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.2926 - acc: 0.9084 - val_loss: 0.5422 - val_acc: 0.8281\n",
            "Epoch 73/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2872 - acc: 0.9120 - val_loss: 0.5404 - val_acc: 0.8324\n",
            "Epoch 74/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2902 - acc: 0.9100 - val_loss: 0.5328 - val_acc: 0.8307\n",
            "Epoch 75/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2844 - acc: 0.9125 - val_loss: 0.5478 - val_acc: 0.8279\n",
            "Epoch 76/100\n",
            "45000/45000 [==============================] - 15s 339us/step - loss: 0.2863 - acc: 0.9122 - val_loss: 0.5451 - val_acc: 0.8303\n",
            "Epoch 77/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.2721 - acc: 0.9171 - val_loss: 0.5337 - val_acc: 0.8341\n",
            "Epoch 78/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.2669 - acc: 0.9173 - val_loss: 0.5374 - val_acc: 0.8326\n",
            "Epoch 79/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2637 - acc: 0.9192 - val_loss: 0.5413 - val_acc: 0.8352\n",
            "Epoch 80/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2633 - acc: 0.9184 - val_loss: 0.5389 - val_acc: 0.8330\n",
            "Epoch 81/100\n",
            "45000/45000 [==============================] - 15s 339us/step - loss: 0.2601 - acc: 0.9212 - val_loss: 0.5331 - val_acc: 0.8339\n",
            "Epoch 82/100\n",
            "45000/45000 [==============================] - 15s 336us/step - loss: 0.2620 - acc: 0.9181 - val_loss: 0.5350 - val_acc: 0.8349\n",
            "Epoch 83/100\n",
            "45000/45000 [==============================] - 15s 338us/step - loss: 0.2569 - acc: 0.9210 - val_loss: 0.5419 - val_acc: 0.8330\n",
            "Epoch 84/100\n",
            "45000/45000 [==============================] - 15s 337us/step - loss: 0.2594 - acc: 0.9210 - val_loss: 0.5413 - val_acc: 0.8318\n",
            "Evaluating model...\n",
            "Test accuracy: 0.828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcyVcoRKKJIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}